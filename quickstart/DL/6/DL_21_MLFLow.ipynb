{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLFlow example\n"
      ],
      "metadata": {
        "id": "-cwe48Z4Z_Rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Логирование sklearn модели"
      ],
      "metadata": {
        "id": "pjqMM27NiOYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "id": "HAJPsRHyjE9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Простое автологирование"
      ],
      "metadata": {
        "id": "H-GaFBsqvcdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "mlflow.autolog()\n",
        "\n",
        "db = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
        "# MLflow triggers logging automatically upon model fitting\n",
        "rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "YH9HlbJgvbmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from mlflow.models import infer_signature\n",
        "import mlflow.sklearn\n",
        "import mlflow.exceptions\n",
        "\n",
        "# Load the Iris dataset\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Define the model hyperparameters\n",
        "params = {\n",
        "  \"solver\": \"lbfgs\",\n",
        "  \"max_iter\": 1000, # Use hydra for configuration management\n",
        "  \"random_state\": 8888}\n",
        "\n",
        "# Train the model\n",
        "lr = LogisticRegression(**params)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "print(accuracy, precision, recall, f1)\n",
        "\n",
        "experiment_name = \"MLflow experiment 01\"\n",
        "run_name = \"run 01\"\n",
        "try:\n",
        "    # Create a new MLflow Experiment\n",
        "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
        "except mlflow.exceptions.MlflowException as e:\n",
        "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
        "    print(experiment_id)\n",
        "\n",
        "with mlflow.start_run(run_name=run_name, experiment_id=experiment_id) as run:\n",
        "    # Log the hyperparameters\n",
        "    mlflow.log_params(params=params)\n",
        "    # Log the performance metrics\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"f1\", f1)\n",
        "    mlflow.log_metrics({\"accuracy\": accuracy,\"f1\": f1})\n",
        "    # Set a tag that we can use to remind ourselves what th\n",
        "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris run was for data\")\n",
        "    # Infer the model signature\n",
        "    signature = infer_signature(X_test, y_test)\n",
        "    # Log the model\n",
        "    model_info = mlflow.sklearn.log_model(\n",
        "      sk_model=lr,\n",
        "      artifact_path=\"iris_model\",\n",
        "      signature=signature,\n",
        "      input_example=X_test,\n",
        "      registered_model_name=\"LR_model_01\",\n",
        "      pyfunc_predict_fn = \"predict_proba\"\n",
        "    )\n",
        "    sk_pyfunc = mlflow.sklearn.load_model(model_uri=model_info.model_uri)\n",
        "    predictions = sk_pyfunc.predict(X_test)\n",
        "    print(predictions)\n",
        "    eval_data = pd.DataFrame(y_test)\n",
        "    eval_data.columns = [\"label\"]\n",
        "    eval_data[\"predictions\"] = predictions\n",
        "\n",
        "    results = mlflow.evaluate(\n",
        "      data=eval_data,\n",
        "      model_type=\"classifier\",\n",
        "      targets= \"label\",\n",
        "      predictions=\"predictions\",\n",
        "      evaluators = [\"default\"])\n",
        "    print(f\"metrics:\\\\n{results.metrics}\")\n",
        "    print(f\"artifacts:\\\\n{results.artifacts}\")"
      ],
      "metadata": {
        "id": "IsWlKoR4h_11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Логирование pytorch модели"
      ],
      "metadata": {
        "id": "m34QPkRQiUu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "\n",
        "net = nn.Linear(10, 1)\n",
        "loss_function = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
        "X = torch.randn(100, 10)\n",
        "y = torch.randn(100, 1)\n",
        "print(X.shape, y.shape)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = loss_function(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    signature = infer_signature(X.numpy(), net(X).detach().numpy())\n",
        "    model_info = mlflow.pytorch.log_model(\n",
        "      pytorch_model = net,\n",
        "      artifact_path = \"pytorch model\",\n",
        "      signature=signature,\n",
        "      input_example=X.numpy(),\n",
        "      registered_model_name=\"pytorch_model\"\n",
        "    )\n",
        "    pytorch_pyfunc = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n",
        "    X_test = torch.randn(20, 10).numpy()\n",
        "    predictions = pytorch_pyfunc.predict(X_test)\n",
        "    print(predictions)\n",
        "    eval_data = pd.DataFrame(y.numpy())\n",
        "    print(eval_data)\n",
        "    eval_data.columns = [\"label\"]\n",
        "    eval_data[\"predictions\"] = net(X).detach().numpy()\n",
        "    print(eval_data.shape)\n",
        "    results = mlflow.evaluate(\n",
        "      data=eval_data,\n",
        "      model_type=\"regressor\",\n",
        "      targets= \"label\",\n",
        "      predictions=\"predictions\",\n",
        "      evaluators = [\"default\"]\n",
        "    )\n",
        "    print(f\"metrics:\\\\n{results.metrics}\")\n",
        "    print(f\"artifacts:\\\\n{results.artifacts}\")"
      ],
      "metadata": {
        "id": "Kc0GNeC0l_dL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}