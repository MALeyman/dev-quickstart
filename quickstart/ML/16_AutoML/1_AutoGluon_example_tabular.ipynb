{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487344de",
   "metadata": {
    "id": "487344de"
   },
   "source": [
    "# AutoGluon Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
    "outputId": "18e76722-caa4-4dad-b1ac-93a8fb4be094",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon.tabular[all]\n",
      "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.0.2)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.14.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
      "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.tabular[all])\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.4.2)\n",
      "Collecting autogluon.core==1.2 (from autogluon.tabular[all])\n",
      "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon.tabular[all])\n",
      "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all])\n",
      "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.tabular[all])\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy<3.8 (from autogluon.tabular[all])\n",
      "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (4.5.0)\n",
      "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.8.1)\n",
      "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.1.4)\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.7.19)\n",
      "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.30.1)\n",
      "Collecting torch<2.6,>=2.2 (from autogluon.tabular[all])\n",
      "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (2.32.3)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (3.10.0)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.tabular[all])\n",
      "  Downloading boto3-1.37.28-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.tabular[all])\n",
      "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (18.1.0)\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
      "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.tabular[all]) (5.9.5)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (0.20.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.29)\n",
      "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.21.0+cu124)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.9)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all])\n",
      "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.15.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (4.13.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
      "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
      "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.5.3)\n",
      "Collecting botocore<1.38.0,>=1.37.28 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
      "  Downloading botocore-1.37.28-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.1.1)\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (8.1.8)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.1.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.29.4)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.5.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.11.15)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.21.1)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (7.1.0)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading virtualenv-20.30.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.71.0)\n",
      "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading memray-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2025.1.31)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all])\n",
      "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.1.5)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision>=0.11 (from fastai<2.8,>=2.3.1->autogluon.tabular[all])\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8->autogluon.tabular[all]) (3.0.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.18.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.17.2)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.3.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.24.0)\n",
      "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading textual-3.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.69.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.26.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.38.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (0.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.0.3)\n",
      "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n",
      "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.37.28-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl (66.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.37.28-py3-none-any.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading memray-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading textual-3.0.1-py3-none-any.whl (681 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.8/681.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-spy, opencensus-context, distlib, colorful, virtualenv, triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, jmespath, tensorboardX, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, blis, scikit-learn, s3transfer, nvidia-cusolver-cu12, aiohttp-cors, torch, thinc, textual, ray, opencensus, catboost, boto3, torchvision, spacy, memray, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 1.2.1\n",
      "    Uninstalling blis-1.2.1:\n",
      "      Successfully uninstalled blis-1.2.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.3.4\n",
      "    Uninstalling thinc-8.3.4:\n",
      "      Successfully uninstalled thinc-8.3.4\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.8.5\n",
      "    Uninstalling spacy-3.8.5:\n",
      "      Successfully uninstalled spacy-3.8.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-cors-0.8.1 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.tabular-1.2 blis-0.7.11 boto3-1.37.28 botocore-1.37.28 catboost-1.2.7 colorful-0.5.6 distlib-0.3.9 jmespath-1.0.1 memray-1.17.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 py-spy-0.4.0 ray-2.39.0 s3transfer-0.11.4 scikit-learn-1.5.2 spacy-3.7.5 tensorboardX-2.6.2.2 textual-3.0.1 thinc-8.2.5 torch-2.5.1 torchvision-0.20.1 triton-3.1.0 virtualenv-20.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install autogluon.tabular[all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8we7sMReIcVK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8we7sMReIcVK",
    "outputId": "e9be6944-bd1e-4e01-8a05-b336c5d98701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1\n",
      "    Uninstalling torchvision-0.20.1:\n",
      "      Successfully uninstalled torchvision-0.20.1\n",
      "Successfully installed torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7yFeSYNpJASL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "7yFeSYNpJASL",
    "outputId": "3bb06278-e919-4ec8-bffa-e0d08e5a20a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.25.0\n",
      "  Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.25.0 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.0 which is incompatible.\n",
      "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.25.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "abad4e4a6f2041129f74cf690c6f587a",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install numpy==1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae7a5f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fae7a5f3",
    "outputId": "0fe173f0-bb6c-4f9b-a005-25d5da226195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "6118              0             0              40   United-States    >50K  \n",
      "23204             0             0               8   United-States   <=50K  \n",
      "29590             0             0              44   United-States   <=50K  \n",
      "18116             0          2339              40     El-Salvador   <=50K  \n",
      "33964         15024             0              40   United-States    >50K  \n",
      "Summary of occupation column: \n",
      " count              1000\n",
      "unique               15\n",
      "top        Craft-repair\n",
      "freq                142\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 1000  # чтобы быстрее работало\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "print(train_data.head())\n",
    "\n",
    "label = 'occupation'\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
    "\n",
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])  # удалить целевой столбец\n",
    "\n",
    "metric = 'accuracy' # измерение метрики для демо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98733672",
   "metadata": {
    "collapsed": false,
    "id": "98733672",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Настройка гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f28cf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c8de3f960a9748d4b70d48ed94cbedaf",
      "550003061b314c029472668a94bbea58",
      "e24c03efc7044841b795032b90345368",
      "77b75ba5e053454eb031f4b8a9692718",
      "c6c80d3504874e29800c5285ee0c2c09",
      "13871d4bc4ea4c54a3838cba9b108767",
      "d2931822646749edbfe60cc3b445a9ad",
      "c529da12d904462fa5a81a5a8eaa8faa",
      "fee6bd4170804a6a94881ee48f3b5edb",
      "584cde0fa59a44ca940092529ec3612a",
      "084d4b1db3fb4e37abafcf2fe78295a8",
      "9109f581456c4fed9f741bf9fb251ce3",
      "974d24a0112e40e0afbb2e04879e9f6a",
      "50decea642b847c18ea0abab0fedd624",
      "cb7e4cacc5704120b50d87bf4bc30808",
      "7cb22b72a9724c02beb99dc6f247a0e0",
      "268e35a4fe6244f4be055a90932306b9",
      "fc87c540302d4845969e05febdf8d040",
      "3fff1c9ae4954a42a94ee2cbe35884ce",
      "f653aedded4843ef9191e73ab8dddb04",
      "671eb28ffc51483e9c2e1280a308d6f6",
      "f8126dac1a944ac8ad3f07dae42a4f48"
     ]
    },
    "id": "87f28cf4",
    "outputId": "3c941fa8-8b77-41fd-b48f-dab1d6586c0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250404_233523\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.87 GB / 12.67 GB (85.8%)\n",
      "Disk Space Avail:   61.53 GB / 107.72 GB (57.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
      "\t\tContext path: \"/content/AutogluonModels/ag-20250404_233523/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   LightGBM_BAG_L1/T1       0.357143   0.366516    accuracy        2.743275       0.142671  42.258078                 2.743275                0.142671          42.258078            1       True          1\n",
      "1  WeightedEnsemble_L3       0.357143   0.366516    accuracy        2.745054       0.148119  42.283541                 0.001779                0.005449           0.025464            3       True          4\n",
      "2  WeightedEnsemble_L2       0.357143   0.366516    accuracy        2.745069       0.150812  42.288758                 0.001794                0.008141           0.030680            2       True          2\n",
      "3   LightGBM_BAG_L2/T1       0.312500   0.306561    accuracy        2.781178       0.281735  85.421906                 0.037904                0.139064          43.163828            2       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t126s\t = DyStack   runtime |\t174s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 174s\n",
      "AutoGluon will save models to \"/content/AutogluonModels/ag-20250404_233523\"\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 14\n",
      "Label Column:       occupation\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 13 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.996\n",
      "Train Data Class Count: 13\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10625.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'num_boost_round': 100, 'num_leaves': Int: lower=26, upper=66, 'learning_rate': Real: lower=0.01, upper=0.3, 'colsample_bytree': Real: lower=0.5, upper=1.0, 'subsample': Real: lower=0.5, upper=1.0}],\n",
      "\t'NN_TORCH': [{'num_epochs': 15, 'learning_rate': Real: lower=0.0001, upper=0.01, 'activation': Categorical['relu', 'softrelu', 'tanh'], 'dropout_prob': Real: lower=0.0, upper=0.5, 'batch_size': Int: lower=32, upper=128, 'optimizer': Categorical['adam', 'sgd']}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 2 L1 models, fit_strategy=\"sequential\" ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 52.16s of the 173.89s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8de3f960a9748d4b70d48ed94cbedaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: LightGBM_BAG_L1/T1 ...\n",
      "\t0.3574\t = Validation score   (accuracy)\n",
      "\t43.67s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ... Tuning model for up to 52.16s of the 127.17s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+\n",
      "| Configuration for experiment     NeuralNetTorch_BAG_L1   |\n",
      "+----------------------------------------------------------+\n",
      "| Search algorithm                 SearchGenerator         |\n",
      "| Scheduler                        FIFOScheduler           |\n",
      "| Number of trials                 10                      |\n",
      "+----------------------------------------------------------+\n",
      "\n",
      "View detailed results here: /content/AutogluonModels/ag-20250404_233523/models/NeuralNetTorch_BAG_L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 23:39:09,643\tINFO timeout.py:54 -- Reached timeout of 52.155646578079455 seconds. Stopping all trials.\n",
      "2025-04-04 23:39:09,691\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/AutogluonModels/ag-20250404_233523/models/NeuralNetTorch_BAG_L1' in 0.0353s.\n",
      "2025-04-04 23:39:19,711\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 2 trial(s):\n",
      "- 4f2ba8e7: FileNotFoundError('Could not fetch metrics for 4f2ba8e7: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20250404_233523/models/NeuralNetTorch_BAG_L1/4f2ba8e7')\n",
      "- 1005cd47: FileNotFoundError('Could not fetch metrics for 1005cd47: both result.json and progress.csv were not found at /content/AutogluonModels/ag-20250404_233523/models/NeuralNetTorch_BAG_L1/1005cd47')\n",
      "No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L1... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 173.90s of the 63.97s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1/T1': 1.0}\n",
      "\t0.3574\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 2 L2 models, fit_strategy=\"sequential\" ...\n",
      "Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 28.76s of the 63.91s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9109f581456c4fed9f741bf9fb251ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n"
     ]
    }
   ],
   "source": [
    "from autogluon.common import space\n",
    "\n",
    "nn_options = {\n",
    "    'num_epochs': 15,  # увеличено для лучшей конвергенции\n",
    "    'learning_rate': space.Real(1e-4, 1e-2, default=5e-4, log=True),\n",
    "    'activation': space.Categorical('relu', 'softrelu', 'tanh'),\n",
    "    'dropout_prob': space.Real(0.0, 0.5, default=0.1),\n",
    "    'batch_size': space.Int(32, 128, default=64),  # добавлено для лучшей производительности\n",
    "    'optimizer': space.Categorical('adam', 'sgd')  # добавлено для выбора оптимизатора\n",
    "}\n",
    "\n",
    "gbm_options = {\n",
    "    'num_boost_round': 100,\n",
    "    'num_leaves': space.Int(lower=26, upper=66, default=36),\n",
    "    'learning_rate': space.Real(0.01, 0.3, default=0.1, log=True),  # добавлено для лучшей настройки\n",
    "    'colsample_bytree': space.Real(0.5, 1.0, default=0.8),  # добавлено для предотвращения переобучения\n",
    "    'subsample': space.Real(0.5, 1.0, default=0.8)  # добавлено для bagging\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'GBM': gbm_options,\n",
    "    'NN_TORCH': nn_options,\n",
    "}\n",
    "\n",
    "time_limit = 5*60  # увеличено для лучшего поиска гиперпараметров\n",
    "num_trials = 10  # увеличено для лучшего поиска гиперпараметров\n",
    "search_strategy = 'bayes'  # улучшен для более эффективного поиска\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler': 'local',\n",
    "    'searcher': search_strategy,\n",
    "    'max_resource': 'auto',  # автоматически определяет доступные ресурсы\n",
    "    'resource_type': 'cpu'  # или 'gpu' если доступно\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data,\n",
    "    time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    presets='best_quality'  # добавлено для лучшего качества модели\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2965a",
   "metadata": {
    "id": "3bf2965a"
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc4fe3",
   "metadata": {
    "id": "1bfc4fe3"
   },
   "outputs": [],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc894bfde6cbc5f1",
   "metadata": {
    "collapsed": false,
    "id": "cc894bfde6cbc5f1",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Ансамблирование stacking/bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821c4af",
   "metadata": {
    "id": "d821c4af"
   },
   "outputs": [],
   "source": [
    "label = 'class'\n",
    "test_data_nolabel = test_data.drop(columns=[label])\n",
    "y_test = test_data[label]\n",
    "save_path = 'agModels-predictClass'\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric=metric,\n",
    "    path=save_path,\n",
    "    verbosity=2  # добавлено для лучшей отладки\n",
    ").fit(\n",
    "    train_data,\n",
    "    num_bag_folds=5,  # кросс-валидация для лучшей оценки\n",
    "    num_bag_sets=2,   # множественные наборы для стабильности\n",
    "    num_stack_levels=2,  # добавлено стекинг для улучшения качества\n",
    "    hyperparameters={\n",
    "        'NN_TORCH': {\n",
    "            'num_epochs': 10,  # увеличено для лучшей конвергенции\n",
    "            'learning_rate': 1e-3,\n",
    "            'batch_size': 128,\n",
    "            'dropout_prob': 0.1\n",
    "        },\n",
    "        'GBM': {\n",
    "            'num_boost_round': 100,  # увеличено для лучшего качества\n",
    "            'num_leaves': 64,\n",
    "            'learning_rate': 0.05\n",
    "        },\n",
    "        'CATB': {  # добавлено для разнообразия моделей\n",
    "            'iterations': 100,\n",
    "            'depth': 6,\n",
    "            'learning_rate': 0.05\n",
    "        }\n",
    "    },\n",
    "    hyperparameter_tune_kwargs={\n",
    "        'num_trials': 10,\n",
    "        'scheduler': 'local',\n",
    "        'searcher': 'bayes',  # улучшен для более эффективного поиска\n",
    "        'max_resource': 'auto',\n",
    "        'time_limit': 3600  # добавлено ограничение по времени\n",
    "    },\n",
    "    presets='best_quality',  # добавлено для лучшего качества\n",
    "    holdout_frac=0.1  # добавлено для раннего останова\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf666c",
   "metadata": {
    "id": "e1cf666c"
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric='balanced_accuracy',\n",
    "    path=save_path,\n",
    "    verbosity=2,  # добавлено для лучшей отладки\n",
    "    problem_type='binary'  # явное указание типа задачи\n",
    ").fit(\n",
    "    train_data,\n",
    "    auto_stack=True,\n",
    "    calibrate_decision_threshold=True,  # включено для лучшей калибровки\n",
    "    hyperparameters={\n",
    "        'FASTAI': {\n",
    "            'num_epochs': 15,\n",
    "            'learning_rate': 1e-3,\n",
    "            'batch_size': 128,\n",
    "            'dropout_prob': 0.1\n",
    "        },\n",
    "        'GBM': {\n",
    "            'num_boost_round': 200,\n",
    "            'num_leaves': 64,\n",
    "            'learning_rate': 0.05,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'subsample': 0.8\n",
    "        },\n",
    "        'CATB': {  # добавлено для разнообразия моделей\n",
    "            'iterations': 200,\n",
    "            'depth': 6,\n",
    "            'learning_rate': 0.05\n",
    "        }\n",
    "    },\n",
    "    hyperparameter_tune_kwargs={\n",
    "        'num_trials': 10,\n",
    "        'scheduler': 'local',\n",
    "        'searcher': 'bayes',  # улучшен для более эффективного поиска\n",
    "        'max_resource': 'auto',\n",
    "        'time_limit': 3600  # добавлено ограничение по времени\n",
    "    },\n",
    "    presets='best_quality',  # добавлено для лучшего качества\n",
    "    holdout_frac=0.1  # добавлено для раннего останова\n",
    ")\n",
    "\n",
    "# Проверка качества модели\n",
    "y_pred = predictor.predict(test_data)\n",
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "print(predictor.leaderboard(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209aed94e755e675",
   "metadata": {
    "collapsed": false,
    "id": "209aed94e755e675",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Работа с результатом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6f148501e94c4",
   "metadata": {
    "id": "10e6f148501e94c4"
   },
   "outputs": [],
   "source": [
    "print(f'Prior to calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
    "scores = predictor.evaluate(test_data)\n",
    "\n",
    "calibrated_decision_threshold = predictor.calibrate_decision_threshold()\n",
    "predictor.set_decision_threshold(calibrated_decision_threshold)\n",
    "\n",
    "print(f'After calibration (predictor.decision_threshold={predictor.decision_threshold}):')\n",
    "scores_calibrated = predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f7817111c6477",
   "metadata": {
    "id": "f18f7817111c6477"
   },
   "outputs": [],
   "source": [
    "for metric_name in scores:\n",
    "    metric_score = scores[metric_name]\n",
    "    metric_score_calibrated = scores_calibrated[metric_name]\n",
    "    decision_threshold = predictor.decision_threshold\n",
    "    print(f'decision_threshold={decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
    "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
    "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
    "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a1bf30667c186",
   "metadata": {
    "id": "251a1bf30667c186"
   },
   "outputs": [],
   "source": [
    "predictor.set_decision_threshold(0.5)  # Reset decision threshold\n",
    "for metric_name in ['f1', 'balanced_accuracy', 'mcc']:\n",
    "    metric_score = predictor.evaluate(test_data, silent=True)[metric_name]\n",
    "    calibrated_decision_threshold = predictor.calibrate_decision_threshold(metric=metric_name, verbose=False)\n",
    "    metric_score_calibrated = predictor.evaluate(\n",
    "        test_data, decision_threshold=calibrated_decision_threshold, silent=True\n",
    "    )[metric_name]\n",
    "    print(f'decision_threshold={calibrated_decision_threshold:.3f}\\t| metric=\"{metric_name}\"'\n",
    "          f'\\n\\ttest_score uncalibrated: {metric_score:.4f}'\n",
    "          f'\\n\\ttest_score   calibrated: {metric_score_calibrated:.4f}'\n",
    "          f'\\n\\ttest_score        delta: {metric_score_calibrated-metric_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc8c19",
   "metadata": {
    "id": "67cc8c19"
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # `predictor.path` is another way to get the relative path needed to later load predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d292a",
   "metadata": {
    "id": "dc1d292a"
   },
   "outputs": [],
   "source": [
    "predictor.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5df1ea",
   "metadata": {
    "id": "2b5df1ea"
   },
   "outputs": [],
   "source": [
    "datapoint = test_data_nolabel.iloc[[0]]  # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "print(datapoint)\n",
    "predictor.predict(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c88edf",
   "metadata": {
    "id": "a9c88edf"
   },
   "outputs": [],
   "source": [
    "predictor.predict_proba(datapoint)  # returns a DataFrame that shows which probability corresponds to which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357da7e2",
   "metadata": {
    "id": "357da7e2"
   },
   "outputs": [],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f02254",
   "metadata": {
    "id": "d5f02254"
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4b79f",
   "metadata": {
    "id": "2cd4b79f"
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard(extra_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39b3b1",
   "metadata": {
    "id": "dc39b3b1"
   },
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f938d89",
   "metadata": {
    "id": "1f938d89"
   },
   "outputs": [],
   "source": [
    "i = 0  # index of model to use\n",
    "model_to_use = predictor.model_names()[i]\n",
    "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
    "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd13fed",
   "metadata": {
    "id": "5cd13fed"
   },
   "outputs": [],
   "source": [
    "all_models = predictor.model_names()\n",
    "model_to_use = all_models[i]\n",
    "specific_model = predictor._trainer.load_model(model_to_use)\n",
    "\n",
    "# Objects defined below are dicts of various information (not printed here as they are quite large):\n",
    "model_info = specific_model.get_info()\n",
    "predictor_information = predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b53a65",
   "metadata": {
    "id": "39b53a65"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494aae6",
   "metadata": {
    "id": "5494aae6"
   },
   "outputs": [],
   "source": [
    "perf = predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffd4bd",
   "metadata": {
    "id": "82ffd4bd"
   },
   "outputs": [],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eced22",
   "metadata": {
    "id": "e2eced22"
   },
   "outputs": [],
   "source": [
    "predictor.persist()\n",
    "\n",
    "num_test = 20\n",
    "preds = np.array(['']*num_test, dtype='object')\n",
    "for i in range(num_test):\n",
    "    datapoint = test_data_nolabel.iloc[[i]]\n",
    "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
    "    preds[i] = pred_numpy[0]\n",
    "\n",
    "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
    "print(\"Predictions: \", preds)\n",
    "\n",
    "predictor.unpersist()  # free memory by clearing models, future predict() calls will load models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845d3cd",
   "metadata": {
    "id": "c845d3cd"
   },
   "outputs": [],
   "source": [
    "# At most 0.05 ms per row (20000 rows per second throughput)\n",
    "infer_limit = 0.00005\n",
    "# adhere to infer_limit with batches of size 10000 (batch-inference, easier to satisfy infer_limit)\n",
    "infer_limit_batch_size = 10000\n",
    "# adhere to infer_limit with batches of size 1 (online-inference, much harder to satisfy infer_limit)\n",
    "# infer_limit_batch_size = 1  # Note that infer_limit<0.02 when infer_limit_batch_size=1 can be difficult to satisfy.\n",
    "predictor_infer_limit = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=30,\n",
    "    infer_limit=infer_limit,\n",
    "    infer_limit_batch_size=infer_limit_batch_size,\n",
    ")\n",
    "\n",
    "# NOTE: If bagging was enabled, it is important to call refit_full at this stage.\n",
    "#  infer_limit assumes that the user will call refit_full after fit.\n",
    "# predictor_infer_limit.refit_full()\n",
    "\n",
    "# NOTE: To align with inference speed calculated during fit, models must be persisted.\n",
    "predictor_infer_limit.persist()\n",
    "# Below is an optimized version that only persists the minimum required models for prediction.\n",
    "# predictor_infer_limit.persist('best')\n",
    "\n",
    "predictor_infer_limit.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a668eac",
   "metadata": {
    "id": "0a668eac"
   },
   "outputs": [],
   "source": [
    "test_data_batch = test_data.sample(infer_limit_batch_size, replace=True, ignore_index=True)\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "predictor_infer_limit.predict(test_data_batch)\n",
    "time_end = time.time()\n",
    "\n",
    "infer_time_per_row = (time_end - time_start) / len(test_data_batch)\n",
    "rows_per_second = 1 / infer_time_per_row\n",
    "infer_time_per_row_ratio = infer_time_per_row / infer_limit\n",
    "is_constraint_satisfied = infer_time_per_row_ratio <= 1\n",
    "\n",
    "print(f'Model is able to predict {round(rows_per_second, 1)} rows per second. (User-specified Throughput = {1 / infer_limit})')\n",
    "print(f'Model uses {round(infer_time_per_row_ratio * 100, 1)}% of infer_limit time per row.')\n",
    "print(f'Model satisfies inference constraint: {is_constraint_satisfied}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcda6fd",
   "metadata": {
    "id": "1dcda6fd"
   },
   "outputs": [],
   "source": [
    "additional_ensembles = predictor.fit_weighted_ensemble(expand_pareto_frontier=True)\n",
    "print(\"Alternative ensembles you can use for prediction:\", additional_ensembles)\n",
    "\n",
    "predictor.leaderboard(only_pareto_frontier=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757a79b",
   "metadata": {
    "id": "a757a79b"
   },
   "outputs": [],
   "source": [
    "model_for_prediction = additional_ensembles[0]\n",
    "predictions = predictor.predict(test_data, model=model_for_prediction)\n",
    "predictor.delete_models(models_to_delete=additional_ensembles, dry_run=False)  # delete these extra models so they don't affect rest of tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158cc13",
   "metadata": {
    "id": "9158cc13"
   },
   "source": [
    "### Работа с моделью бэггинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ea890",
   "metadata": {
    "id": "fd8ea890"
   },
   "outputs": [],
   "source": [
    "refit_model_map = predictor.refit_full()\n",
    "print(\"Name of each refit-full model corresponding to a previous bagged ensemble:\")\n",
    "print(refit_model_map)\n",
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8854f",
   "metadata": {
    "id": "13d8854f"
   },
   "outputs": [],
   "source": [
    "student_models = predictor.distill(time_limit=30)  # specify much longer time limit in real applications\n",
    "print(student_models)\n",
    "preds_student = predictor.predict(test_data_nolabel, model=student_models[0])\n",
    "print(f\"predictions from {student_models[0]}:\", list(preds_student)[:5])\n",
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a36ab",
   "metadata": {
    "id": "ba4a36ab"
   },
   "source": [
    "### Пресеты для гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5e5e4",
   "metadata": {
    "id": "3bd5e5e4"
   },
   "outputs": [],
   "source": [
    "presets = ['good_quality', 'optimize_for_deployment']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e808d32",
   "metadata": {
    "id": "3e808d32"
   },
   "outputs": [],
   "source": [
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2298e4",
   "metadata": {
    "id": "ae2298e4"
   },
   "outputs": [],
   "source": [
    "excluded_model_types = ['KNN', 'NN_TORCH']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "084d4b1db3fb4e37abafcf2fe78295a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13871d4bc4ea4c54a3838cba9b108767": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "268e35a4fe6244f4be055a90932306b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fff1c9ae4954a42a94ee2cbe35884ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50decea642b847c18ea0abab0fedd624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fff1c9ae4954a42a94ee2cbe35884ce",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f653aedded4843ef9191e73ab8dddb04",
      "value": 0
     }
    },
    "550003061b314c029472668a94bbea58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13871d4bc4ea4c54a3838cba9b108767",
      "placeholder": "​",
      "style": "IPY_MODEL_d2931822646749edbfe60cc3b445a9ad",
      "value": "  0%"
     }
    },
    "584cde0fa59a44ca940092529ec3612a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671eb28ffc51483e9c2e1280a308d6f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77b75ba5e053454eb031f4b8a9692718": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_584cde0fa59a44ca940092529ec3612a",
      "placeholder": "​",
      "style": "IPY_MODEL_084d4b1db3fb4e37abafcf2fe78295a8",
      "value": " 0/10 [00:43&lt;?, ?it/s]"
     }
    },
    "7cb22b72a9724c02beb99dc6f247a0e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9109f581456c4fed9f741bf9fb251ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_974d24a0112e40e0afbb2e04879e9f6a",
       "IPY_MODEL_50decea642b847c18ea0abab0fedd624",
       "IPY_MODEL_cb7e4cacc5704120b50d87bf4bc30808"
      ],
      "layout": "IPY_MODEL_7cb22b72a9724c02beb99dc6f247a0e0"
     }
    },
    "974d24a0112e40e0afbb2e04879e9f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_268e35a4fe6244f4be055a90932306b9",
      "placeholder": "​",
      "style": "IPY_MODEL_fc87c540302d4845969e05febdf8d040",
      "value": "  0%"
     }
    },
    "c529da12d904462fa5a81a5a8eaa8faa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6c80d3504874e29800c5285ee0c2c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8de3f960a9748d4b70d48ed94cbedaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_550003061b314c029472668a94bbea58",
       "IPY_MODEL_e24c03efc7044841b795032b90345368",
       "IPY_MODEL_77b75ba5e053454eb031f4b8a9692718"
      ],
      "layout": "IPY_MODEL_c6c80d3504874e29800c5285ee0c2c09"
     }
    },
    "cb7e4cacc5704120b50d87bf4bc30808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_671eb28ffc51483e9c2e1280a308d6f6",
      "placeholder": "​",
      "style": "IPY_MODEL_f8126dac1a944ac8ad3f07dae42a4f48",
      "value": " 0/10 [00:00&lt;?, ?it/s]"
     }
    },
    "d2931822646749edbfe60cc3b445a9ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e24c03efc7044841b795032b90345368": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c529da12d904462fa5a81a5a8eaa8faa",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fee6bd4170804a6a94881ee48f3b5edb",
      "value": 0
     }
    },
    "f653aedded4843ef9191e73ab8dddb04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8126dac1a944ac8ad3f07dae42a4f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc87c540302d4845969e05febdf8d040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fee6bd4170804a6a94881ee48f3b5edb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
